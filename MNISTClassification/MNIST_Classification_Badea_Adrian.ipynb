{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TJrO-_7hMY4B",
        "WMuqkm0RiyJC"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8S-SdxDWzJ_D"
      },
      "source": [
        "\n",
        "## Assignment 2 - MNIST classification\n",
        "\n",
        "Train a convolutional neural network to predict the number of digits from MNIST Count dataset in three ways :\n",
        "\n",
        "- Without training on the count dataset, but on the 28x28 dataset\n",
        "- By training on the count dataset, while assessing number of layers, loss function, regularisation\n",
        "- Using transfer learning, one time with weights randomly initialized and another time pretrained on the MNIST dataset. Compare acuraccies while using 20%, 50%, 100% of training data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epDB8XX7HLmy"
      },
      "source": [
        "\n",
        "## Method 1 - Sliding window\n",
        "#### Without training on the count dataset, we will train the CNN on 28x28 and then continue on the test dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA5bE8IgeXbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fc59d01-f8ab-4990-9410-9e1d5e4de1be"
      },
      "source": [
        "from __future__ import print_function\n",
        "import argparse\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from IPython.core.debugger import set_trace\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNhG8VL0P-Ls"
      },
      "source": [
        "### Defining training settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xe3Z-6nfBby"
      },
      "source": [
        "kwargs={}\n",
        "\n",
        "class Args():\n",
        "  def __init__(self):\n",
        "      self.batch_size = 500\n",
        "      self.test_batch_size = 128\n",
        "      self.epochs = 5\n",
        "      self.lr = 0.005\n",
        "      self.momentum = 0.9\n",
        "      self.seed = 1\n",
        "      self.log_interval = int(30000 / self.batch_size)\n",
        "      self.cuda = False\n",
        "\n",
        "args = Args()\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "torch.manual_seed(args.seed)\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': False} if use_cuda else {}\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSPvPhN9z_yf"
      },
      "source": [
        "### CNN arhitecture\n",
        "\n",
        "The architecture of the model will be\n",
        "  - conv layer: 20 filters, kernel size: 5x5, stride:1\n",
        "  - relu\n",
        "  - max pool: kernel size: 2x2, stride:1\n",
        "  - conv layer: 50 filters, kernel size: 5x5, stride:1\n",
        "  - relu\n",
        "  - max pool: kernel size: 2x2, stride:1\n",
        "  - fully connected: 500 neurons\n",
        "  - relu\n",
        "  - log softmax\n",
        "\n",
        "\n",
        "\n",
        "1.   input : (batch_size, 28 x 28)\n",
        "2.   output : 10 values - probabilities for every digit\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwxfGRluebjs"
      },
      "source": [
        "no_filters1 = 20\n",
        "no_filters2 = 50\n",
        "no_neurons1 = 500\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = no_filters1, kernel_size = 5, stride = 1)\n",
        "        self.conv2 = nn.Conv2d(no_filters1, no_filters2, 5, 1)\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features = 4 * 4 * no_filters2, out_features = no_neurons1)\n",
        "        self.fc2 = nn.Linear(in_features = no_neurons1, out_features = 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "      \n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        x = x.view(-1, 4*4*no_filters2)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return F.log_softmax(x, dim=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qd4c0kf_fM5d"
      },
      "source": [
        "Loading MNIST dataset containing drawn digits with a total of 50k training samples and 10k testing samples. Each image has one channel and 28x28 pixels.\n",
        "\n",
        "Loading pickle data for 100x100 classification\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ynOv7v0EuGG",
        "outputId": "aa24f33c-f5f8-499d-c912-d8d1bd87d763"
      },
      "source": [
        "!rm MNIST.tar.gz*\n",
        "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
        "!tar -zxvf MNIST.tar.gz\n",
        "!ls\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-01 18:06:34--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
            "--2021-04-01 18:06:34--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
            "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-gzip]\n",
            "Saving to: ‘MNIST.tar.gz’\n",
            "\n",
            "MNIST.tar.gz            [        <=>         ]  33.20M  6.70MB/s    in 14s     \n",
            "\n",
            "2021-04-01 18:06:48 (2.35 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
            "\n",
            "MNIST/\n",
            "MNIST/raw/\n",
            "MNIST/raw/train-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-labels-idx1-ubyte\n",
            "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "MNIST/raw/train-images-idx3-ubyte\n",
            "MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "MNIST/raw/t10k-images-idx3-ubyte\n",
            "MNIST/raw/train-images-idx3-ubyte.gz\n",
            "MNIST/processed/\n",
            "MNIST/processed/training.pt\n",
            "MNIST/processed/test.pt\n",
            "gdrive\tMNIST  MNIST.tar.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJrO-_7hMY4B"
      },
      "source": [
        "### Data loader for MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A_euLmSfGWY"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./', train=True, download=True,\n",
        "                   transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                       \n",
        "                   ])),\n",
        "    batch_size=args.batch_size, shuffle=True,drop_last=True, **kwargs)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('./', train=False, transform=transforms.Compose([\n",
        "                       transforms.ToTensor(),\n",
        "                   ])),\n",
        "    batch_size=args.test_batch_size, shuffle=False,drop_last=True, **kwargs)\n",
        "\n",
        "first_train_batch_imgs, first_train_batch_labels = next(iter(train_loader))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pWAKQ6ORT0_X"
      },
      "source": [
        "### Training the CNN for MNIST classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llHthpCfefit"
      },
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    \n",
        "    model.train()\n",
        "    all_losses = []\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data, target = data, target.long()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        all_losses.append(loss.detach().cpu().numpy())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "            \n",
        "    return np.array(all_losses).mean()\n",
        "\n",
        "def test(args, model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        num_iter = 0\n",
        "        for data, target in test_loader:\n",
        "            data, target = data, target.long()\n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += F.nll_loss(output, target)\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).float().mean().item()\n",
        "            num_iter += 1\n",
        "\n",
        "    test_loss /= num_iter\n",
        "    test_accuracy = 100. * correct / num_iter\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.format(\n",
        "        test_loss,\n",
        "        test_accuracy))\n",
        "    return test_loss, test_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvKyqameBaO7"
      },
      "source": [
        "### Optimizer and call the training / testing  functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opQ8sJzecVYu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0438325b-832e-4909-a0e1-e29d1fecf8c3"
      },
      "source": [
        "model_mnist = CNN()\n",
        "optimizer = optim.SGD(model_mnist.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "\n",
        "losses_train = []\n",
        "losses_test = []\n",
        "accuracy_test = []\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "  \n",
        "    train_loss = train(args, model_mnist, device, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = test(args, model_mnist, device, test_loader)\n",
        "\n",
        "    losses_train.append(train_loss)\n",
        "    losses_test.append(test_loss)\n",
        "    accuracy_test.append(test_accuracy)\n",
        "\n",
        "def plot_loss(loss, label, color='blue'):\n",
        "    pyplot.plot(loss, label=label, color=color)\n",
        "    pyplot.legend()\n",
        "\n",
        "pyplot.figure(1)\n",
        "plot_loss(losses_train,'train_loss','red')\n",
        "plot_loss(losses_test,'test_loss')\n",
        "pyplot.figure(2)\n",
        "plot_loss(accuracy_test,'test_accuracy')\n",
        "\n",
        "\n",
        "path_to_pretrained = \"mnist_cnn.pt\"\n",
        "\n",
        "print(\"Model's state_dict:\")\n",
        "for param_tensor in model_mnist.state_dict():\n",
        "    print(param_tensor, \"\\t\", model_mnist.state_dict()[param_tensor].size())\n",
        "\n",
        "torch.save(model_mnist.state_dict(), path_to_pretrained)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.306841\n",
            "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 2.069250\n",
            "\n",
            "Test set: Average loss: 0.4764, Accuracy: (86%)\n",
            "\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.439727\n",
            "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.326216\n",
            "\n",
            "Test set: Average loss: 0.2507, Accuracy: (92%)\n",
            "\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.199198\n",
            "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.248276\n",
            "\n",
            "Test set: Average loss: 0.1842, Accuracy: (95%)\n",
            "\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.242898\n",
            "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.170640\n",
            "\n",
            "Test set: Average loss: 0.1391, Accuracy: (96%)\n",
            "\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.141205\n",
            "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.125823\n",
            "\n",
            "Test set: Average loss: 0.1173, Accuracy: (96%)\n",
            "\n",
            "Model's state_dict:\n",
            "conv1.weight \t torch.Size([20, 1, 5, 5])\n",
            "conv1.bias \t torch.Size([20])\n",
            "conv2.weight \t torch.Size([50, 20, 5, 5])\n",
            "conv2.bias \t torch.Size([50])\n",
            "fc1.weight \t torch.Size([500, 800])\n",
            "fc1.bias \t torch.Size([500])\n",
            "fc2.weight \t torch.Size([10, 500])\n",
            "fc2.bias \t torch.Size([10])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMuqkm0RiyJC"
      },
      "source": [
        "### Sliding Window method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJFywcJPJe14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "57c3dcfd-fff7-4e40-dc3d-c71e9b79c1a2"
      },
      "source": [
        "\n",
        "print(first_train_batch_imgs.shape)\n",
        "\n",
        "f, axarr = pyplot.subplots(1,5)\n",
        "for i in range(5):\n",
        "  axarr[i].imshow(first_train_batch_imgs[i,0])\n",
        "print(f'Labels of the shown images: {first_train_batch_labels[:5]}')\n",
        "\n",
        "with torch.no_grad() :\n",
        "\n",
        "    output = np.e**model_mnist(first_train_batch_imgs[4].reshape(1, 1, 28, 28))\n",
        "    print('Predicted : {}'.format(torch.argmax(output)))\n",
        "    print(torch.max(output))\n",
        "    print(output)\n",
        "    print(torch.sum(output))\n",
        "    \n",
        "    \n",
        "    axarr[i].imshow(first_train_batch_imgs[i,0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([500, 1, 28, 28])\n",
            "Labels of the shown images: tensor([6, 1, 4, 0, 7])\n",
            "Predicted : 7\n",
            "tensor(0.9997)\n",
            "tensor([[1.4158e-07, 5.6912e-07, 6.4480e-05, 1.6712e-04, 2.3572e-08, 1.2275e-07,\n",
            "         1.0397e-11, 9.9973e-01, 8.0135e-07, 3.8636e-05]])\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 5 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OL6Ch69JLUue"
      },
      "source": [
        "### Data loader for MNIST, count dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kuiFjRZnch8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85b221d7-b92c-44e5-938d-19c9c0d90748"
      },
      "source": [
        "import pickle\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def get_large_dataset(path, max_batch_idx=100, shuffle=False, first_k=5000):\n",
        "\n",
        "  with open(path,'rb') as handle:\n",
        "    data = pickle.load(handle)\n",
        "\n",
        "  np_dataset_large  = np.expand_dims(data['images'],1)[:first_k]\n",
        "  np_dataset_no_count = data['no_count'].astype(np.float32)[:first_k]\n",
        "  \n",
        "  print(f'np_dataset_large shape: {np_dataset_large.shape}')\n",
        "  \n",
        "  dataset_large, dataset_no_count= map(torch.tensor, \n",
        "                (np_dataset_large, np_dataset_no_count))\n",
        "\n",
        "  '''\n",
        "  dataset_large = dataset_large.to(device)\n",
        "  dataset_no_count = dataset_no_count.to(device)\n",
        "  '''\n",
        "  \n",
        "  large_dataset = TensorDataset(dataset_large, dataset_no_count)\n",
        "  large_data_loader = DataLoader(large_dataset, batch_size=args.batch_size, shuffle=shuffle, drop_last=True)\n",
        "  \n",
        "  return large_data_loader\n",
        "\n",
        "path_train = 'gdrive/MyDrive/Adi/mnist_count_train.pickle'\n",
        "path_test = 'gdrive/MyDrive/Adi/mnist_count_test.pickle'\n",
        "\n",
        "large_data_loader_train = get_large_dataset(path_train, max_batch_idx=50,shuffle=True, first_k=5000)\n",
        "large_data_loader_test = get_large_dataset(path_test, max_batch_idx=50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "np_dataset_large shape: (5000, 1, 100, 100)\n",
            "np_dataset_large shape: (1000, 1, 100, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h7Jm3OuVac4"
      },
      "source": [
        "We want to find the number of digits in the image by taking advantage of the previous trained network for classification of 28x28 MNIST digits. We will define a threshold after which we would predict the 28x28 is a digit.\n",
        "\n",
        "We slide with 2 on the horizontal axis and 3 on the vertical axis of the 100 x 100 image in search for a 28x28 digit (so 72/2 * 72/3)\n",
        "\n",
        "\n",
        "Results:\n",
        "\n",
        "Threshold start point : 0.99\n",
        "\n",
        "  - For 5 epochs train : 0.34 best\n",
        "  - For 10 epochs train : 0.3 best\n",
        "  - For more epochs, the model predicts hot-ones\n",
        "\n",
        "The threshold grows adaptively from 0.99 with respect to acuraccy\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3BUtyvJxGBL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feec6b12-f44b-4027-8ebd-1ebe51915ed9"
      },
      "source": [
        "big_image_size = 100\n",
        "small_image_size = 28\n",
        "\n",
        "args.batch_size = 500\n",
        "def predict_number_of_digits(batch, slidex = 2, slidey = 3):\n",
        "\n",
        "  predicted_counts = torch.zeros(batch.shape[0])\n",
        " \n",
        "  num_predictions = 0\n",
        "  map = torch.zeros(batch.shape[0], 10)\n",
        " \n",
        "  for i in range(0, big_image_size - small_image_size, slidex):\n",
        "    for j in range(0, big_image_size - small_image_size, slidey):\n",
        "\n",
        "        num_predictions += 1\n",
        "        if num_predictions % 200 == 0:\n",
        "            print(\"For this batch, {}th prediction\".format(num_predictions))\n",
        "\n",
        "        part = batch[:, :, i : i + small_image_size, j : j + small_image_size]\n",
        "        part = part.float() / 255.0\n",
        "\n",
        "        with torch.no_grad():  \n",
        "           output = np.e**model_mnist(part.detach().cpu())\n",
        "\n",
        "           pred = output.argmax(dim=1, keepdim=True)\n",
        "            \n",
        "\n",
        "           for k in range(0, batch.shape[0]):\n",
        "\n",
        "              if output[k][pred[k]] >= threshold:\n",
        "                  map[k][pred[k]] = 1\n",
        "  \n",
        "  for i in range(0, batch.shape[0]):\n",
        "      for j in range(0, 10):\n",
        "          if map[i][j] == 1:\n",
        "\n",
        "             predicted_counts[i] += 1\n",
        "             if predicted_counts[i] >= 5:\n",
        "                  predicted_counts[i] = 5\n",
        "  \n",
        "  print(\"Next batch\")\n",
        "\n",
        "  return predicted_counts\n",
        "\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "steps = 3\n",
        "opt = 0.01\n",
        "acuraccy = 0\n",
        "threshold = 0.99\n",
        "maximum_acuraccy = 0\n",
        "\n",
        "\n",
        "while steps != 0:\n",
        "\n",
        "  print(\"First batch:\")\n",
        "  for local_batch, local_labels in large_data_loader_test:\n",
        "\n",
        "      local_batch, local_labels = local_batch, local_labels\n",
        "      predicted_labels = predict_number_of_digits(local_batch.float())\n",
        "      total += predicted_labels.shape[0]\n",
        "\n",
        "      for i in range(predicted_labels.shape[0]):\n",
        "          if predicted_labels[i] == local_labels[i]:\n",
        "            correct += 1\n",
        "  new_acuraccy = correct / total\n",
        "  print(\"Acuraccy is : {}\".format(new_acuraccy))\n",
        "\n",
        "  if new_acuraccy > maximum_acuraccy :\n",
        "    maximum_acuraccy = new_acuraccy\n",
        "\n",
        "  opt /= 2\n",
        "  print(opt)\n",
        "  if new_acuraccy < acuraccy : \n",
        "      opt = -opt\n",
        "  \n",
        "  acuraccy = new_acuraccy\n",
        "  threshold = threshold + opt\n",
        "  steps -= 1\n",
        "\n",
        "  print(\"New threshold is : {}\".format(threshold))\n",
        "\n",
        "\n",
        "print(\"Maximum acuraccy is : {}\".format(maximum_acuraccy))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "First batch:\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "Acuraccy is : 0.335\n",
            "0.005\n",
            "New threshold is : 0.995\n",
            "First batch:\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "Acuraccy is : 0.327\n",
            "0.0025\n",
            "New threshold is : 0.9925\n",
            "First batch:\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "For this batch, 200th prediction\n",
            "For this batch, 400th prediction\n",
            "For this batch, 600th prediction\n",
            "For this batch, 800th prediction\n",
            "Next batch\n",
            "Acuraccy is : 0.3406666666666667\n",
            "-0.00125\n",
            "New threshold is : 0.9912500000000001\n",
            "Maximum acuraccy is : 0.3406666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wWeG0nwHhC5"
      },
      "source": [
        "## Method 2 - Convolutional neural network on MNIST - Count\n",
        "\n",
        "Similar arhitecture, two convolutions and then three fully connected layers\n",
        "Using Cross Entropy Loss for classification of five classes (1, 2, 3, 4 or 5 digits)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXcrPBV-PqxF"
      },
      "source": [
        "### Training settings for count dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnccOOtBPkh_"
      },
      "source": [
        "\n",
        "class Args():\n",
        "  def __init__(self):\n",
        "      self.batch_size = 500\n",
        "      self.test_batch_size = 500\n",
        "      self.epochs = 20\n",
        "      self.lr = 0.1\n",
        "      self.momentum = 0.9\n",
        "      self.seed = 1\n",
        "      self.log_interval = 4\n",
        "      self.cuda = False\n",
        "\n",
        "\n",
        "kwargs={}\n",
        "\n",
        "args = Args()\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYl9E0akzzQc"
      },
      "source": [
        "### CNN arhitecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPkZSFsdKBn2"
      },
      "source": [
        "no_filters1 = 20\n",
        "no_filters2 = 50\n",
        "no_neurons1 = 1024\n",
        "no_neurons2 = 128\n",
        "\n",
        "class CNN_count(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 1, out_channels = no_filters1, kernel_size = 5, stride = 1)\n",
        "        self.conv2 = nn.Conv2d(in_channels = no_filters1, out_channels = no_filters2, kernel_size = 5, stride = 1)\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features = 22 * 22 * no_filters2, out_features = no_neurons1)\n",
        "        self.fc2 = nn.Linear(in_features = no_neurons1, out_features = no_neurons2)\n",
        "        self.fc3 = nn.Linear(in_features = no_neurons2, out_features = 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        \n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2, 2)\n",
        "        \n",
        "        x = x.view(-1, 22 * 22 * no_filters2)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQZnfkqF5xcP"
      },
      "source": [
        "### Training on count dataset, with and without regularisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7kbq325VjxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2291dd54-06fb-44ec-ca28-c16472e1a264"
      },
      "source": [
        "def train_count(args, model, train_loader, optimizer, epoch):\n",
        "        \n",
        "        model.train()\n",
        "        all_losses = []\n",
        "        batch_id = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "        print(\"Train starting...\")\n",
        "        for data, target in train_loader:\n",
        "            batch_id += 1\n",
        "    \n",
        "            data, target = data.float() / 255.0, target.long() - 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "                \n",
        "            output = model(data)\n",
        "    \n",
        "            loss = criterion(output, target)\n",
        "    \n",
        "            all_losses.append(loss.detach().cpu().numpy())\n",
        "            loss.backward()\n",
        "    \n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch_id % args.log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_id * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_id / len(train_loader), loss.item()))\n",
        "                \n",
        "        return np.array(all_losses).mean()\n",
        "    \n",
        "def test_count(args, model, test_loader):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        num_iter = 0\n",
        "        for data, target in test_loader:\n",
        "\n",
        "            data, target = data.float() / 255.0, target.long() - 1\n",
        "            \n",
        "            output = model(data)\n",
        "            \n",
        "            test_loss += criterion(output, target)\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).float().mean().item()\n",
        "\n",
        "            num_iter += 1\n",
        "\n",
        "    test_loss /= num_iter\n",
        "    test_accuracy = 100. * correct / num_iter\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.format(\n",
        "        test_loss,\n",
        "        test_accuracy))\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "def train_and_test(regularisation = False, decay = 0.001):\n",
        "\n",
        "    acuraccies = []\n",
        "    fractions = [0.2, 0.5, 1.0]\n",
        "\n",
        "    for k in fractions:\n",
        "        \n",
        "        round_k = int(5000 * k)\n",
        "        large_data_loader_train = get_large_dataset(path_train, max_batch_idx=50, shuffle=True, first_k=round_k)\n",
        "        large_data_loader_test = get_large_dataset(path_test, max_batch_idx=50) \n",
        "       \n",
        "        model = CNN_count()\n",
        "\n",
        "        if regularisation == True: \n",
        "          optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum,weight_decay = decay)\n",
        "        else:\n",
        "          optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "          \n",
        "        losses_train = []\n",
        "        losses_test = []\n",
        "        accuracy_test = []\n",
        "        last_accuracy = 0\n",
        "        \n",
        "        for epoch in range(1, args.epochs + 1):\n",
        "          \n",
        "            train_loss = train_count(args, model, large_data_loader_train, optimizer, epoch)\n",
        "        \n",
        "            test_loss, test_accuracy = test_count(args, model, large_data_loader_test)\n",
        "        \n",
        "            losses_train.append(train_loss)\n",
        "            losses_test.append(test_loss)\n",
        "            accuracy_test.append(test_accuracy)\n",
        "            last_accuracy = test_accuracy\n",
        "        \n",
        "        acuraccies.append(last_accuracy)\n",
        "        \n",
        "        def plot_loss(loss, label):\n",
        "            pyplot.plot(loss, label=label)\n",
        "            pyplot.legend()\n",
        "        \n",
        "        \n",
        "        pyplot.figure(2)\n",
        "        plot_loss(accuracy_test,'test_accuracy' + str(k))\n",
        "            \n",
        "    pyplot.figure(2)\n",
        "    if regularisation == False:\n",
        "      pyplot.title('MNIST Accuracies without regularisation')\n",
        "    else:\n",
        "      pyplot.title('MNIST Accuraccies with regularisation')\n",
        "    print()\n",
        "    pyplot.show()\n",
        "\n",
        "    pl, ax = pyplot.subplots(1, 1)\n",
        "    ax.plot(fractions, acuraccies, 'r-', lw=3, alpha=0.6, label='Acuraccy with respect to data usage')\n",
        "    pyplot.show()\n",
        "    print()\n",
        "\n",
        "\n",
        "train_and_test(regularisation = False)\n",
        "train_and_test(regularisation = True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "np_dataset_large shape: (1000, 1, 100, 100)\n",
            "np_dataset_large shape: (1000, 1, 100, 100)\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6104, Accuracy: (18%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6089, Accuracy: (18%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6067, Accuracy: (25%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6037, Accuracy: (26%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.5974, Accuracy: (26%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.5858, Accuracy: (27%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.5594, Accuracy: (28%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.5654, Accuracy: (29%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 2.7308, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6184, Accuracy: (21%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6130, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6121, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6120, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6114, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6103, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6097, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6094, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6091, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6092, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "\n",
            "Test set: Average loss: 1.6094, Accuracy: (18%)\n",
            "\n",
            "np_dataset_large shape: (2500, 1, 100, 100)\n",
            "np_dataset_large shape: (1000, 1, 100, 100)\n",
            "Train starting...\n",
            "Train Epoch: 1 [2000/2500 (80%)]\tLoss: 1.609483\n",
            "\n",
            "Test set: Average loss: 1.6091, Accuracy: (19%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 2 [2000/2500 (80%)]\tLoss: 1.605561\n",
            "\n",
            "Test set: Average loss: 1.6050, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 3 [2000/2500 (80%)]\tLoss: 1.598094\n",
            "\n",
            "Test set: Average loss: 1.5938, Accuracy: (26%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 4 [2000/2500 (80%)]\tLoss: 1.567697\n",
            "\n",
            "Test set: Average loss: 1.5525, Accuracy: (30%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 5 [2000/2500 (80%)]\tLoss: 1.476207\n",
            "\n",
            "Test set: Average loss: 2.9595, Accuracy: (21%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 6 [2000/2500 (80%)]\tLoss: 1.617391\n",
            "\n",
            "Test set: Average loss: 1.6131, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 7 [2000/2500 (80%)]\tLoss: 1.612106\n",
            "\n",
            "Test set: Average loss: 1.6118, Accuracy: (19%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 8 [2000/2500 (80%)]\tLoss: 1.611222\n",
            "\n",
            "Test set: Average loss: 1.6107, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 9 [2000/2500 (80%)]\tLoss: 1.608413\n",
            "\n",
            "Test set: Average loss: 1.6109, Accuracy: (18%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 10 [2000/2500 (80%)]\tLoss: 1.612395\n",
            "\n",
            "Test set: Average loss: 1.6107, Accuracy: (18%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 11 [2000/2500 (80%)]\tLoss: 1.608556\n",
            "\n",
            "Test set: Average loss: 1.6083, Accuracy: (18%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 12 [2000/2500 (80%)]\tLoss: 1.605921\n",
            "\n",
            "Test set: Average loss: 1.6070, Accuracy: (19%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 13 [2000/2500 (80%)]\tLoss: 1.604429\n",
            "\n",
            "Test set: Average loss: 1.6041, Accuracy: (26%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 14 [2000/2500 (80%)]\tLoss: 1.598883\n",
            "\n",
            "Test set: Average loss: 1.5995, Accuracy: (26%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 15 [2000/2500 (80%)]\tLoss: 1.585983\n",
            "\n",
            "Test set: Average loss: 1.5889, Accuracy: (24%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 16 [2000/2500 (80%)]\tLoss: 1.564294\n",
            "\n",
            "Test set: Average loss: 1.5702, Accuracy: (24%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 17 [2000/2500 (80%)]\tLoss: 1.709234\n",
            "\n",
            "Test set: Average loss: 1.6835, Accuracy: (21%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 18 [2000/2500 (80%)]\tLoss: 1.617808\n",
            "\n",
            "Test set: Average loss: 1.6093, Accuracy: (21%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 19 [2000/2500 (80%)]\tLoss: 1.609238\n",
            "\n",
            "Test set: Average loss: 1.6087, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 20 [2000/2500 (80%)]\tLoss: 1.607793\n",
            "\n",
            "Test set: Average loss: 1.6113, Accuracy: (20%)\n",
            "\n",
            "np_dataset_large shape: (5000, 1, 100, 100)\n",
            "np_dataset_large shape: (1000, 1, 100, 100)\n",
            "Train starting...\n",
            "Train Epoch: 1 [2000/5000 (40%)]\tLoss: 1.607363\n",
            "Train Epoch: 1 [4000/5000 (80%)]\tLoss: 1.608275\n",
            "\n",
            "Test set: Average loss: 1.6031, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 2 [2000/5000 (40%)]\tLoss: 1.595471\n",
            "Train Epoch: 2 [4000/5000 (80%)]\tLoss: 1.573457\n",
            "\n",
            "Test set: Average loss: 1.5339, Accuracy: (29%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 3 [2000/5000 (40%)]\tLoss: 2.660563\n",
            "Train Epoch: 3 [4000/5000 (80%)]\tLoss: 1.613414\n",
            "\n",
            "Test set: Average loss: 1.6124, Accuracy: (21%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 4 [2000/5000 (40%)]\tLoss: 1.615637\n",
            "Train Epoch: 4 [4000/5000 (80%)]\tLoss: 1.611010\n",
            "\n",
            "Test set: Average loss: 1.6090, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 5 [2000/5000 (40%)]\tLoss: 1.607301\n",
            "Train Epoch: 5 [4000/5000 (80%)]\tLoss: 1.610414\n",
            "\n",
            "Test set: Average loss: 1.6086, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 6 [2000/5000 (40%)]\tLoss: 1.608120\n",
            "Train Epoch: 6 [4000/5000 (80%)]\tLoss: 1.607850\n",
            "\n",
            "Test set: Average loss: 1.6068, Accuracy: (20%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 7 [2000/5000 (40%)]\tLoss: 1.604146\n",
            "Train Epoch: 7 [4000/5000 (80%)]\tLoss: 1.604206\n",
            "\n",
            "Test set: Average loss: 1.6020, Accuracy: (22%)\n",
            "\n",
            "Train starting...\n",
            "Train Epoch: 8 [2000/5000 (40%)]\tLoss: 1.596716\n",
            "Train Epoch: 8 [4000/5000 (80%)]\tLoss: 1.586153\n",
            "\n",
            "Test set: Average loss: 1.5681, Accuracy: (30%)\n",
            "\n",
            "Train starting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRK-4zKEHgdq"
      },
      "source": [
        "## Transfer learning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj93kYl6CTYr"
      },
      "source": [
        "class Args():\n",
        "  def __init__(self):\n",
        "      self.batch_size = 500\n",
        "      self.test_batch_size = 64\n",
        "      self.epochs = 5\n",
        "      self.lr = 0.001\n",
        "      self.momentum = 0.9\n",
        "      self.seed = 1\n",
        "      self.log_interval = int(1000 / self.batch_size)\n",
        "      self.cuda = False\n",
        "\n",
        "\n",
        "kwargs={}\n",
        "\n",
        "args = Args()\n",
        "args.log_interval /= 10\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm8_J13uJE3J"
      },
      "source": [
        "no_filters1 = 20\n",
        "no_filters2 = 50\n",
        "no_neurons1 = 500\n",
        "no_features = 19 * 19 * 5\n",
        "\n",
        "class CNN_pretrained(nn.Module):\n",
        "  def __init__(self):\n",
        "\n",
        "      super().__init__()\n",
        "      self.conv1 = nn.Conv2d(1, no_filters1, 5, 1)\n",
        "      \n",
        "      self.conv2 = nn.Conv2d(no_filters1, no_filters2, 5, 1)\n",
        "      \n",
        "      self.fully_conv1  = nn.Conv2d(no_filters2, no_neurons1, 4)\n",
        "\n",
        "      self.fully_conv2_new = nn.Conv2d(no_neurons1, 5, 1)\n",
        "      \n",
        "      self.linear_loc = nn.Linear(no_features, 1)\n",
        "\n",
        "  def forward(self, xb):\n",
        "\n",
        "      x = xb.view(-1, 1, xb.shape[2], xb.shape[3])\n",
        "      x = F.relu(self.conv1(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = F.relu(self.conv2(x))\n",
        "      x = F.max_pool2d(x, 2, 2)\n",
        "      x = F.relu(self.fully_conv1(x))\n",
        "      \n",
        "      self.conv_act = self.fully_conv2_new(x).view(args.batch_size,-1)\n",
        "\n",
        "      self.lin = self.linear_loc(self.conv_act)\n",
        "      self.final = F.relu(self.lin)\n",
        "      return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGl3LEn-CQR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01346cab-d327-472e-b468-f2f17a3568a7"
      },
      "source": [
        "model_pretrained = CNN_pretrained()\n",
        "path_to_pretrained = 'mnist_cnn.pt'\n",
        "loaded_state_dict = torch.load(path_to_pretrained)\n",
        "\n",
        "model_dict = {}\n",
        "for key,val in loaded_state_dict.items():\n",
        "  \n",
        "  key = key.replace('fc','fully_conv')\n",
        "\n",
        "  print(f'key: {key}')\n",
        "\n",
        "  if 'fully_conv1.weight' in key:\n",
        "    val = val.view(-1,no_filters2, 4, 4)\n",
        "  if 'fully_conv2.weight' in key:\n",
        "    val = val.view(-1, no_neurons1, 1, 1)\n",
        "  \n",
        "  model_dict[key] = val\n",
        "  \n",
        "\n",
        "model_pretrained.load_state_dict(model_dict, strict=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "key: conv1.weight\n",
            "key: conv1.bias\n",
            "key: conv2.weight\n",
            "key: conv2.bias\n",
            "key: fully_conv1.weight\n",
            "key: fully_conv1.bias\n",
            "key: fully_conv2.weight\n",
            "key: fully_conv2.bias\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=['fully_conv2_new.weight', 'fully_conv2_new.bias', 'linear_loc.weight', 'linear_loc.bias'], unexpected_keys=['fully_conv2.weight', 'fully_conv2.bias'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic_gADDqEOfJ"
      },
      "source": [
        "optimizer_loc_pretrained = optim.SGD(\n",
        "    loc_model_pretrained.parameters(), lr=args.lr, momentum=args.momentum)\n",
        "\n",
        "losses_train_pre = []\n",
        "losses_test_pre = []\n",
        "\n",
        "\n",
        "def train_transfer(args, model, train_loader, optimizer, epoch):\n",
        "        \n",
        "        model.train()\n",
        "        all_losses = []\n",
        "        batch_id = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "        print(\"Train starting...\")\n",
        "        for data, target in train_loader:\n",
        "            batch_id += 1\n",
        "    \n",
        "            data, target = data.float() / 255.0, target.long() - 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "                \n",
        "            output = model(data)\n",
        "    \n",
        "            loss = criterion(output, target)\n",
        "    \n",
        "            all_losses.append(loss.detach().cpu().numpy())\n",
        "            loss.backward()\n",
        "    \n",
        "            optimizer.step()\n",
        "            \n",
        "            if batch_id % args.log_interval == 0:\n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_id * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_id / len(train_loader), loss.item()))\n",
        "                \n",
        "        return np.array(all_losses).mean()\n",
        "    \n",
        "def test_transfer(args, model, test_loader):\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        num_iter = 0\n",
        "        for data, target in test_loader:\n",
        "\n",
        "            data, target = data.float() / 255.0, target.long() - 1\n",
        "            \n",
        "            output = model(data).detach().cpu()\n",
        "            \n",
        "            test_loss += criterion(output, target)\n",
        "\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(target.view_as(pred)).float().mean().item()\n",
        "\n",
        "            num_iter += 1\n",
        "\n",
        "    test_loss /= num_iter\n",
        "    test_accuracy = 100. * correct / num_iter\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: ({:.0f}%)\\n'.format(\n",
        "        test_loss,\n",
        "        test_accuracy))\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "\n",
        "def train_and_test(regularisation = False, decay = 0.001):\n",
        "\n",
        "    acuraccies = []\n",
        "    fractions = [0.2, 0.5, 1.0]\n",
        "\n",
        "    for k in fractions:\n",
        "        \n",
        "        round_k = int(5000 * k)\n",
        "        large_data_loader_train = get_large_dataset(path_train, max_batch_idx=50, shuffle=True, first_k=round_k)\n",
        "        large_data_loader_test = get_large_dataset(path_test, max_batch_idx=50) \n",
        "       \n",
        "        model = model_pretrained\n",
        "\n",
        "        if regularisation == True: \n",
        "          optimizer = optim.Adam(model.parameters(), lr=args.lr, weight_decay = decay)\n",
        "        else:\n",
        "          optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "          \n",
        "        losses_train = []\n",
        "        losses_test = []\n",
        "        accuracy_test = []\n",
        "        last_accuracy = 0\n",
        "        \n",
        "        for epoch in range(1, args.epochs + 1):\n",
        "          \n",
        "            train_loss = train_transfer(args, model, large_data_loader_train, optimizer, epoch)\n",
        "        \n",
        "            test_loss, test_accuracy = test_transfer(args, model, large_data_loader_test)\n",
        "        \n",
        "            losses_train.append(train_loss)\n",
        "            losses_test.append(test_loss)\n",
        "            accuracy_test.append(test_accuracy)\n",
        "            last_accuracy = test_accuracy\n",
        "        \n",
        "        acuraccies.append(last_accuracy)\n",
        "        \n",
        "        def plot_loss(loss, label):\n",
        "            pyplot.plot(loss, label=label)\n",
        "            pyplot.legend()\n",
        "        \n",
        "        \n",
        "        pyplot.figure(2)\n",
        "        plot_loss(accuracy_test,'test_accuracy' + str(k))\n",
        "            \n",
        "    pyplot.figure(2)\n",
        "    if regularisation == False:\n",
        "      pyplot.title('MNIST Accuracies without regularisation')\n",
        "    else:\n",
        "      pyplot.title('MNIST Accuraccies with regularisation')\n",
        "    print()\n",
        "    pyplot.show()\n",
        "\n",
        "    pl, ax = pyplot.subplots(1, 1)\n",
        "    ax.plot(fractions, acuraccies, 'r-', lw=3, alpha=0.6, label='Acuraccy with respect to data usage')\n",
        "    pyplot.show()\n",
        "    print()\n",
        "\n",
        "\n",
        "train_and_test(regularisation = False)\n",
        "train_and_test(regularisation = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}